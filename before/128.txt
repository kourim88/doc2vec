
ベルマン方程式

ベルマン方程式（ベルマンほうていしき、）は、「動的計画法(Dynamic programming)」として知られる数学的最適化において、最適性の必要条件を表す方程式であり、発見者のリチャード・ベルマンにちなんで命名された。動的計画方程式 (dynamic programming equation)とも呼ばれる。 ベルマン方程式は、決定問題(decision problem)において、ある時刻の初期選択と、それ以降の決定問題の価値との関係を記述する。これにより、動的な最適化問題を、「ベルマンの最適性の原理」が示す指針にしたがって、より単純な部分問題(subproblems)に分解するのである。

ベルマン方程式は最初、制御工学や他の応用数学上の問題に適用され、その後、経済理論(economic theory)における重要なツールとなった。しかしながら、動的計画法の基本概念はもともとジョン・フォン・ノイマンとオスカー・モルゲンシュテルンの"ゲーム理論と経済活動" やエイブラハム・ウォールドの 時系列解析（Sequential Analysis) の研究の中で次第に形作られてきたものである。

最適制御理論で解かれるほとんどの問題は、適切なベルマン方程式を用いて解くことができる。 ただし、一般に「ベルマン方程式」という用語は離散時間の最適化問題を解く際に用いられる動的計画法の方程式を指す。 連続時間の最適化問題を解く場合には、ベルマン方程式の連続時間形式である偏微分方程式を用い、これをハミルトン-ヤコビ-ベルマン方程式と呼ぶ。

ベルマン方程式を理解するには、いくつかの背景となる概念を理解しなくてはならない。 第一に、最適化問題は何らかの目標を持つ。具体例を挙げれば、移動時間を最短にする、コストを最小に抑える、利益を最大化する、効用を最大化する、などである。これらの目標を数学の関数で表現したものを 目的関数 (objective function) と呼ぶ。

動的計画法は複数段階にわたる計画問題を、各時点の簡単な手順へと分解する。そのため、ある時点でなされた決定がそれ以降どのように影響を及ぼすか正しく記述しなくてはならない。正しい判断を下すために必要な現在の状況を示す情報を 状態 (state) と呼ぶ。例えば、人がある時点で何をどれだけ消費するか決めるには、（何よりもまず）現在の富（資産額）を知らなくてはならない。 そのゆえ、富は、経済活動を行う人が持つ""の一つと考えられる。言うまでもなく、このような状態変数は他にも存在する。

任意の時点で選ぶことのできる変数を通常 (control variables) と呼ぶ。 例えば、人々は与えられた富のもとで、どれだけ消費すべきか判断する。制御変数を選ぶことは、次の状態を選択することでもある。ただし、一般に次の状態は制御変数だけではなく他の要因によっても影響を受ける。具体例で示そう。最も単純には、今日の富（状態）と消費（制御変数）によって明日の富（次の状態）が決まる。だが、多くの場合、明日の富には別の要因（例：予期せぬボーナス、天災など）も影響するであろう。

動的計画法は、与えられたどんな状態に対しても、適切な制御の指針を与えるような最適な計画を記述する。一例として、消費 formula_1 が富 formula_2 だけに依存する場合には、我々は、財産の関数として消費を決定するような制御則 formula_3 を探索することになる。 状態に基づいて制御変数を決定するこのような関数を、方策関数 (policy function)（Bellman、1957、Ch. III.2を参照)と呼ぶ。

最後に、最適な決定ルール（制御則）はその定義から、実現可能な最良の目的関数の値をもたらすものである。例えば、ある人が与えられた富のもと、満足度を最大化するための消費活動を選ぶとしよう。ただし、満足度 formula_4 は効用関数(utility function)のような目的関数で表現できるとする。この時、各時刻の財産はそれで実現可能な満足度の最大値 formula_5 と関係付けることができる。ある状態で実現しうる最良の目的関数の値を示す関数を 価値関数 (value function) と呼ぶ。

リチャード・ベルマンは、離散時間形式の動的最適化問題が、ある時刻の価値関数とその次の時刻の価値関数の間の関係式を書き下すことによって、再帰的な、(backward induction)と呼ばれる逐次的な形式で表現できることを示した。上述の時間的に隣接する二つの価値関数の関係式がベルマン方程式である。このアプローチでは、終端時刻における最適な方策は、その時刻の状態変数の関数としてすでに決まっており、結果として得られる目的関数の最適値は状態変数で与えられる。次に、最後から一つ前の時刻の最適化を考えると、決定に際して、その状態変数に付随する最適な方策のもとで、その時刻の目的関数と未来の目的関数の和を最大化する。このアルゴリズムは、再帰的に時間を遡る形で進み、初期時刻において、初期状態の関数としての決定ルールが初期時刻に固有の目的関数と2番目のステップの価値関数（第2ステップ以降すべての未来の価値）の和の最適化計算によって得られるまで繰り返される。ゆえに、各ステップにおける決定は、それ以降の未来すべての判断が最適である事を前提として行われるのである。

時刻 formula_6 における状態を formula_7とする。時刻0から始まる決定問題において、初期状態 formula_8 は与えられているものとする。任意の時間において、選択可能なアクションはその時の状態の関数であり、formula_9 と表すことができる。formula_10 は一つ以上の制御変数を表している。アクション formula_11 が選ばれると、それによって状態は formula_12 から新しい状態 formula_13 へと変化するものとする。さらに、状態 formula_12 においてアクション formula_11 をとった時の損得を formula_16 で表す。最後に、我々は性急さ（せっかちさ）の度合いが、（discount factor）formula_17 で表されるものとする。

これらの仮定の下で、無限の未来までを考慮した決定問題（無限期間の最適化問題) は次式となる。

ただし次の条件のもとで：

想定された拘束条件のもとで目的関数を最適化した結果としての、最適な値を表現するものとして formula_20 を定義したことに注意しよう。この関数を「価値関数 (value function)」と呼ぶ。最適値は初期状態によって変化するから、価値関数 formula_21 は初期状態 formula_8 の関数となる。

動的計画法は、この決定問題をより小さな部分問題に分割する。リチャード・ベルマンの「最適性の原理」がその方法を示している：

最適性の原理（Principle of Optimality） ： 最適な方策は、初期状態と初期決定がどんなものであれ、その結果得られる次の状態に関して、以降の決定が必ず最適方策になっているという性質をもつ。 (参照：　Bellman, 1957、Chap. III.3.)

コンピュータ・サイエンスでは、このように分割できる問題の事を「（optimal substructure）を持つ」と表現する。 この原理は、動的ゲーム理論における部分ゲーム完全均衡（subgame perfect equilibrium）と相似な概念である。ただし、動的ゲーム理論における最適方策は、相手プレイヤーが同様に最適方策を選択するという前提に立つ。

最適性の原理から示唆されるように、我々は将来の選択（時刻1から新しい状態 formula_23 でスタートする）について一旦保留して、最初の決定だけを独立に検討する。将来の決定に関する項を大括弧の中に集めることにより、先の問題は次のように表現される。

ただし次の条件のもとで：

ここで時刻1での状態が formula_26 となることを知りつつ、アクション formula_27 を選ぶ。この新しい状態は、時刻1以降すべての決定に影響を与える。 未来全体の決定問題は、右側の角括弧の中に現れている。

これまでのところ、我々は単に現在の決定を未来の決定から分割することによって、単に問題を厄介にしたにすぎないように見える。だが、右側の角括弧の中を状態 formula_26 から始まった時点1における意思決定問題の"価値"として表せたことで、問題の単純化が可能になっている。

従って、問題を価値関数に関する再帰的な定義式として書き直すことができる。

ただし次の条件のもとで：

これがベルマン方程式である。時間に関する添え字を省略し、次の状態を代入することにより、式をより単純化できる。

ベルマン方程式を解くことは、未知の関数 formula_32（価値関数）を見出すことである。ゆえにベルマン方程式は汎関数方程式に属している。価値関数は目的の実現可能な最良値を状態 formula_12 の関数として表していることを思い出そう。価値関数を計算することによって、同時に我々は最適なアクションを状態の関数 formula_34 として得ることができる。これを方策関数(policy function)と呼ぶ。

決定論的な条件では、上述の問題を解くために動的計画法以外の手法を用いることが出来る。ある種の問題に対しては、この手法は便利であるが、確率過程のもつ性質に注意する必要がある。

経済学における具体的な例題として、時刻 formula_35 において初期富（初期資産）formula_27 を持ち、無限の寿命を持つ消費者を考える。彼は、瞬間的効用関数 formula_37 を持つとする。ただし、formula_1 は消費額を表し、次の時刻における割引率を formula_39 とする。時刻 formula_6 において消費されなかった富は、金利 formula_41 と共に次の時刻に繰り越される。すると消費者の効用最大化問題は、消費計画 formula_42 を次式によって決定する問題となる。

ただし次の条件のもとで：

および

最初の条件は、問題設定に記述された資本の蓄積を示し、二つ目の条件は消費者が人生の終わりに置いて負債を先送りできないというを示す。 ベルマン方程式は次式となる。

この代わりに、同じ問題を例えばハミルトン方程式で扱う事もできる。

今、金利が時間とともに変化するとすれば、消費者は確率的最適化問題に直面する。金利 formula_41 がマルコフ過程に従い、その推移確率測度を formula_48、ただし、formula_49 を現在の金利が formula_41 の時に次の時刻の金利の変動を決定する確率測度であるとしよう。このモデルでは、現在の金利が示された直後に、消費者が決定を下すものとする。

この場合、単純な消費の系列 formula_42 を選ぶ代わりに、消費者は彼／彼女の全人生にわたる効用の期待値が最大となるように formula_42 を各時点でのあり得る利率 formula_53 に応じて選ばなくてはならない。

期待値 formula_55 は、金利 formula_41 の系列に関してformula_57で与えられる確率測度に関して計算される。formula_41 はマルコフ過程なので、問題は動的計画法によって劇的に単純化される。ベルマン方程式は単に以下の形となる。

ある一般的な仮定のもとで、結果として得られる最適な方策関数 formula_60 は可測となる。 

マルコフ的なショックを伴い、主体が事後に選択を行うような一般的な確率的時系列の最適化問題に対しては、ベルマン方程式は非常に良く似た形をとる。


経済学において最初にベルマン方程式を適用した例として知られるのが、Martin Beckmann と Richard Muth の研究である。さらに、Martin Beckmann はベルマン方程式を利用した消費理論に関する論文を1959年に発表した。彼の仕事は、特にエドムンド・フェルプスに影響を受けたものである。

ベルマン方程式の経済学への応用として、特に有名なのがロバート・マートンが1973年に発表した 異時点間CAPMである （マートンのポートフォリオ問題もまた参照)。マートンの理論モデルにおいて、投資家が現在の収入と将来の収入もしくはキャピタルゲインを比較して判断をおこなう場合の解はベルマン方程式となる。動的計画法を経済学に応用する場合、結果として得られるベルマン方程式は差分方程式となるため、経済学者は動的計画法を「再帰的方法」と呼ぶ。そのため現在では、「」は、経済学の一分野として認識されている。

ナンシー・ストーキー、ロバート・ルーカス、エドワード・プレスコットは確率的／非確率的動的計画法について細部まで詳細に記述し、さまざまな条件における解の存在定理を得た。彼らは同時に再帰的手法を用いて経済学理論のさまざまな問題のモデル化について多くの例を示した。 この著作は経済学における様々な問題を解くために動的計画法を利用する道を開いた。例えば、最適な経済成長は、資源開発、プリンシパル＝エージェント理論、公共財政、事業投資、資産価格、供給要因、産業組織である。 とトーマス・サージェントは金融政策、 財政政策、 課税、 経済成長、サーチ理論、 労働経済学などにおける様々な理論的問題を研究するために動的計画法を用いた。アビナッシュ・ディキシットとは、資本予算について考察することでこの手法の価値を示した。Andersonはこの手法を非公開企業を含んだ事業評価技術に適用した。

具体的な問題を解くために動的計画法を利用するには、観測できない割引率（discount rate）の決定のような、情報上の困難によって複雑なものになる。 さらに取りうる膨大な数のアクションと状態変数によって生ずる「次元の呪い」に起因する計算技術上の問題が、最適戦略を得る前に立ちはだかる。このような計算上の問題については、Miranda と Fackler、あるいは Meyn 2007 を見よ。

マルコフ決定過程(MDP) において、ベルマン方程式は期待報酬（expected reward）に関する再帰的な関係を表現する。例えば、特定の状態 formula_62 において方策 formula_63 を適用した際の期待報酬は以下のベルマン方程式を満たす:

この方程式は、ある方策 formula_63 のもとで得られる期待報酬を表している。

最適な方策を採用した場合の方程式が最適ベルマン方程式である:

この式は、最適な行動をとった場合に得られる期待報酬を表す。



